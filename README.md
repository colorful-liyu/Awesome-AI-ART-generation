# Awesome-AI-ART-generation
This is a  collection of resources on AI-AR-ART generation with slides!

We are AI300 lab in ECE of Shanghai Jiao Tong University, and this is the sharing papers of research meeting and group discussion, including slides maded by ourselves.

## Contributing

If you think I have missed out on something (or) have any suggestions (papers, implementations and other resources), feel free to pull a request.

Feedback and contributions are welcome!

## GAN models

Papers | Conference | Year | Code | Speaker |Slides
:-------------------------------------------------------:|:------:|:----:|:----:|:------------------:|:----:|
[Alias-Free Generative Adversarial Networks (StyleGAN3)](https://arxiv.org/abs/2106.12423)  | ICCV | 2021 | [here](https://github.com/NVlabs/stylegan3) | Xiaohang Wang | [here](https://1drv.ms/p/s!AlS0P3vuVTvigzN1tENqJ7I6-fgL?e=LNdqOa) 
[Anycost GANs for Interactive Image Synthesis and Editing](https://arxiv.org/abs/2103.03243)   |   CVPR   |     2021      |   [here](https://github.com/mit-han-lab/anycost-gan)  |   Yutian Liu  | x 
[CoCosNet v2: Full-Resolution Correspondence Learning for Image Translation](https://arxiv.org/abs/2012.02047)  |CVPR | 2021 | [here](https://github.com/microsoft/CoCosNet-v2) | Jiyao Mao | [here](https://1drv.ms/p/s!AlS0P3vuVTvigzHLrLegglUWRcPL?e=XS46dI) 
[Projected GANs Converge Faster](https://arxiv.org/abs/2111.01007)   |   NIPS   |     2021      |   [here](https://github.com/autonomousvision/projected_gan)  |   Yuhan Li  | [here](https://1drv.ms/p/s!AlS0P3vuVTvigzabp4-izhOKhtuh?e=OgaS12) 
[GAN-Supervised Dense Visual Alignment](https://arxiv.org/abs/2112.05143)   |   arXiv   |     2021      |   [here](https://github.com/wpeebles/gangealing)  |   Yuhan Li  | [here](https://1drv.ms/p/s!AlS0P3vuVTvigzd_qzNmfcws_Jdu?e=wTlcfU) 
[HifiFace: 3D Shape and Semantic Prior Guided High Fidelity Face Swapping](https://arxiv.org/abs/2106.09965)   |   IJCAI   |     2021      |   [here](https://github.com/mindslab-ai/hififace)  |   Yutian Liu  | [here](https://1drv.ms/p/s!AlS0P3vuVTvigzqnvJ8rX1sCpyWZ?e=032RMi) 
[Correction Filter for Single Image Super-Resolution: Robustifying Off-the-Shelf Deep Super-Resolvers](https://arxiv.org/abs/1912.00157)   |   CVPR   |     2020      |   [here](https://www.catalyzex.com/redirect?url=https://github.com/shadyabh/Correction-Filter)  |   Xiaohang Wang  | [here](https://1drv.ms/p/s!AlS0P3vuVTvigzkllK_O_bL-4ZOI?e=co6IXH) 


## DDPM related models

Papers | Conference | Year | Code | Speaker |Slides
:-------------------------------------------------------:|:------:|:----:|:----:|:------------------:|:----:|
[ILVR: Conditioning Method for Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2108.02938)   | ICCV   |     2021      |   [here](https://github.com/jychoi118/ilvr_adm) |  Jiyao Mao   | [here](https://1drv.ms/p/s!AlS0P3vuVTvigzHLrLegglUWRcPL?e=XS46dI) 
[Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239)   | NIPS   |     2020      |   [here](https://github.com/hojonathanho/diffusion) |  Zhilin Zeng   | [here](https://1drv.ms/p/s!AlS0P3vuVTvigzDpKqZGk2wH5b6h?e=ivIBLm) 
[Vector Quantized Diffusion Model for Text-to-Image Synthesis](https://arxiv.org/abs/2111.14822)   | arXiv   |     2021      |   [here](https://github.com/microsoft/VQ-Diffusion) |  Zhilin Zeng   | [here](https://1drv.ms/p/s!AlS0P3vuVTvigzDpKqZGk2wH5b6h?e=ivIBLm) 


## Deep Compression

Papers | Conference | Year | Code | Speaker |Slides
:-------------------------------------------------------:|:------:|:----:|:----:|:------------------:|:----:|
A survey about Deep Compression   |  x  |       x    |   x |  Yutian Liu   | [here](https://1drv.ms/b/s!AlS0P3vuVTvigzyrarUJtYsLko1l?e=CP2KL2) 


## Text to image and CLIP

Papers | Conference | Year | Code | Speaker |Slides
:-------------------------------------------------------:|:------:|:----:|:----:|:------------------:|:----:|
[CLIP: Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/abs/2103.00020)   | arXiv   |     2021      |   [here](https://github.com/OpenAI/CLIP) |  Zhilin Zeng   | [here](https://github.com/orpatashnik/StyleCLIP) 
[StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery](https://openaccess.thecvf.com/content/ICCV2021/html/Patashnik_StyleCLIP_Text-Driven_Manipulation_of_StyleGAN_Imagery_ICCV_2021_paper.html)   | ICCV   |     2021      |   [here](https://github.com/orpatashnik/StyleCLIP) |  Zhilin Zeng   | [here](https://github.com/orpatashnik/StyleCLIP) 

